consider this pandas data frame: 	time	MP	change	bucket
0	1.680896e+12	17.61	NaN	precursor
1	1.680896e+12	17.61	-3.975014e-04	precursor
2	1.680896e+12	17.60	-1.703578e-04	precursor
3	1.680896e+12	17.59	-5.681818e-04	precursor
0	1.680896e+12	17.59	0.000000e+00	surge
1	1.680896e+12	17.59	0.000000e+00	surge
2	1.680896e+12	17.59	0.000000e+00	surge
3	1.680896e+12	17.59	3.979534e-04	surge
4	1.680896e+12	17.60	1.705514e-04	surge
4	1.680896e+12	17.60	-1.136364e-04	precursor
5	1.680896e+12	17.60	1.137010e-04	surge
6	1.680896e+12	17.60	1.704545e-04	surge
7	1.680896e+12	17.61	3.977273e-04	surge
5	1.680896e+12	17.61	-5.678592e-05	precursor
8	1.680896e+12	17.60	5.685045e-05	surge
9	1.680896e+12	17.62	7.384429e-04	surge
10	1.680896e+12	17.63	3.972758e-04	surge
11	1.680896e+12	17.63	3.970505e-04	surge
12	1.680897e+12	17.64	1.701645e-04	surge
13	1.680897e+12	17.64	0.000000e+00	surge
14	1.680897e+12	17.64	0.000000e+00	surge  for  row within the bucket column, 
identify rows with contiguous,  values which are the same. For those blocks of contiguous,  
same 'bucket' values, Count the number of contiguous rows and put the length of that 
in new column called 'length'. Then add up the sum of all the values in the change column 
for those rows and place that some value into a new column called 'sum'. Create a new 
column called 'identifier' which is equivalent to the minimum 'time' column for that group of rows.
 create a new column called 'end_time' which is equivalent to the maximum 'time' column for that group of rows.
 Create a new column call 'type' which is equivalent to the value in the 'bucket' column which the rows share in common.



For all the unique values in the sequence_df Data frame column 'identifier', 
take only one row from the data frame with that identifier